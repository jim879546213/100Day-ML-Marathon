{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as plt \n",
    "from matplotlib.pylab import rcParams #主要作用为指定图片像素\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回歸問題\n",
    "## 常見的評估指標有\n",
    "[\n",
    "    \n",
    "    \n",
    "MAE\n",
    "    \n",
    "    \n",
    "MSE\n",
    "    \n",
    "    \n",
    "R-square\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "我們隨機生成(X, y)資料，然後使用線性回歸模型做預測，再使用 MAE, MSE, R-square 評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  2.841797252565566\n",
      "MSE:  12.48868006739824\n",
      "R-square:  0.9916581036260311\n"
     ]
    }
   ],
   "source": [
    "#生成資料\n",
    "x,y = datasets.make_regression(n_features = 1, random_state = 42, noise = 4)\n",
    "#建立模型\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "prediction = model.predict(x)\n",
    "\n",
    "#分數衡量\n",
    "mae = metrics.mean_absolute_error(prediction,y) # 使用 MAE 評估\n",
    "mse = metrics.mean_squared_error(prediction,y) # 使用 MSE 評估\n",
    "r2 = metrics.r2_score(prediction,y) # 使用 r-square 評估\n",
    "print(\"MAE: \", mae)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"R-square: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題\n",
    "常見的評估指標有\n",
    "\n",
    "AUC\n",
    "F1-Score (Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我們使用 sklearn 內含的乳癌資料集\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,test_size = 50, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test) # 測試集中的 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.random.random((50,)) # 我們先隨機生成 50 筆預測值，範圍都在 0~1 之間，代表機率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5880025  0.48860553 0.56759145 0.30485135 0.94313733 0.81329894\n",
      " 0.37997101 0.12324029 0.38284734 0.45484232 0.56493799 0.21017244\n",
      " 0.52609333 0.36341143 0.01590238 0.04694656 0.34821803 0.70620199\n",
      " 0.20236366 0.63801455 0.91778978 0.73785752 0.92756671 0.34136844\n",
      " 0.26619033 0.07185341 0.2758851  0.13629695 0.7487705  0.70137163\n",
      " 0.26969933 0.49509568 0.31490121 0.37185576 0.03095422 0.51159489\n",
      " 0.62294848 0.83987852 0.84377792 0.02219743 0.24101127 0.25399664\n",
      " 0.91725884 0.0508385  0.61653381 0.29065041 0.92760784 0.58508022\n",
      " 0.17032694 0.61624063]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC :  0.45500848896434637\n"
     ]
    }
   ],
   "source": [
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "# 使用 roc_auc_score 來評估。 **這邊特別注意 y_pred 必須要放機率值進去!**\n",
    "print(\"AUC : \",auc) # 得到結果約 0.5，與亂猜的結果相近，因為我們的預測值是用隨機生成的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.45283018867924524\n",
      "Precision:  0.5454545454545454\n",
      "Recall:  0.3870967741935484\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred_binarized = np.where(y_pred>threshold, 1, 0) # 使用 np.where 函數, 將 y_pred > 0.5 的值變為 1，小於 0.5 的為 0\n",
    "f1 = metrics.f1_score(y_test, y_pred_binarized) # 使用 F1-Score 評估\n",
    "precision = metrics.precision_score(y_test, y_pred_binarized) # 使用 Precision 評估\n",
    "recall = metrics.recall_score(y_test, y_pred_binarized) # 使用 recall 評估\n",
    "print(\"F1-Score: \", f1) \n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業重點]\n",
    "了解 F1-score 的公式意義，並試著理解程式碼\n",
    "\n",
    "# 作業\n",
    "請參考 F1-score 的公式與原始碼，試著寫出 F2-Score 的計算函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score 其實是 F-Score 中的 β 值為 1 的特例，代表 Precision 與 Recall 的權重相同\n",
    "\n",
    "\n",
    "The general formula for non-negative real $\\beta$ is :\n",
    "\n",
    "$$F_\\beta = \\frac{(1+\\beta^2)\\cdot(precision\\cdot recall)}{(\\beta^2 \\cdot precision+recall)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.random.randint(2, size=100)  # 生成 100 個隨機的 0 / 1 prediction\n",
    "y_true = np.random.randint(2, size=100)  # 生成 100 個隨機的 0 / 1 ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.5294117647058824\n",
      "Recall :  0.627906976744186\n",
      "F2_score :  0.6053811659192825\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_true, y_pred)\n",
    "recall = metrics.recall_score(y_true, y_pred)\n",
    "F2_score = ((1+2**2)*precision*recall)/(2**2*precision+recall)\n",
    "print('Precision : ',precision)\n",
    "print('Recall : ',recall)\n",
    "print('F2_score : ',F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
